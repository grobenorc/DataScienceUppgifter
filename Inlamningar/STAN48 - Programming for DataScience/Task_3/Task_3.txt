############################################################################################################################################
#																	   #
#								R - Code							   	   #
#																	   #
############################################################################################################################################

# Preamble
# Make sure working directory as well as all the scripts:
  # 1. print_triangle.R
  # 2. find_pos.R
  # 3. Fibonacci.R
  # 4. Fibonacci.cpp
  # are stored in the same folder as the working directory

setwd('xxx')



# Task 20 ===========================================================================================================================================
#########################################################################################
# Exercise 20 (R & Python Lecture_6)
# One can use the command line to uppload a function. 
# For example, %run / source (Python/R) print_triangle would upload the function 
# defined above (see Lecture notes) if it is saved in a separate script with the name print_triangle.py / print_triangle.R (Python/R) . 
# Please, create such a script and run this script to upload the function defined in it. 
# Then invoke the function with several different values of the input.
#########################################################################################

source('print_triangle.R') # Make sure script-file is in the folder as the working directory.

# Task 21 ===========================================================================================================================================
#########################################################################################
# Exercise 21 (Python Lecture_6)
# Create a script only with the function find_pos (see Lecture notes) saved in a separate 
# script that has the same name as the function. 
# Run this script to upload the definition. 
# Then invoke the function with several different values of 
# the input list of different lengths. Consider both real and integer numbers 
# in the input list.
#########################################################################################
#================================
# find_pos=function(v,x){
#   for (i in 1:length(v)){
#     if (v[i]>=x){
#       return(i)
#     }
#   }
# }
# 
# v=c(1,2,5,10)
# print(find_pos(v,-1))
# print(find_pos(v,4))
# print(find_pos(v,11))
#================================
source('find_pos.R')
print(find_pos(seq(100),-1))
print(find_pos(seq(100),8))
print(find_pos(seq(1000),986))
print(find_pos(seq(0, 100, length.out = 100), 25.67))
print(find_pos(seq(0, 100, length.out = 1000), 98.6))


# Task 22 ===========================================================================================================================================
#########################################################################################
# Exercise 22 (Python Lecture_6)
# Modify the function find_pos so that it takes either list or 1-D
# array as the first argument, yields a tuple of two elements 
# (L,L+1) if the second argument x of the function 
# satisfies v[L]<=x<v[L+1], or ('-Inf',0) if x is smaller than 
# all elements in the first argument v, or (len(v),'Inf') 
# if x is larger than all elements in the list v. 
# Additionally to the index range, the function should also return 
# the corresponding value range.
#########################################################################################

# One dimensional array in R will only return the legnth of the array meaning we can check that it a one-dimensional array by looking at the length of the dimensions. 
# length(dim(array)) == 1 if one-dimensional, length(array) != 1d otherwise
# Define a function that finds the index and value range for a given value, x, within a 1-dimensional array or vector
find_pos_mod <- function(variable, x) {
  # Check if the input 'variable' is a valid 1-dimensional array or vector
  if (!(is.vector(variable) || (is.array(variable) && length(dim(variable)) == 1) || (is.list(variable) && length(variable) > 0))) {
    stop("Parameter must be a 1-dimensional array or vector")
  }
  
  # Initialize variables to store the index and value range
  index_range <- NULL
  value_range <- NULL
  
  # Loop through the elements of the 'variable'
  for (i in 1:(length(variable) - 1)) {
    # Check if 'x' is within the range of the current element and the next element
    if (x >= variable[i] && x <= variable[i + 1]) {
      # Set the index range and value range
      index_range <- c(i, i + 1)
      value_range <- c(variable[i], variable[i + 1])
      break  # Exit the loop once a match is found
    }
  }
  
  # If 'index_range' and 'value_range' are still NULL, it means 'x' falls outside the range
  if (is.null(index_range) || is.null(value_range)) {
    # Check if 'x' is less than or equal to the first element
    if (x <= variable[1]) {
      index_range <- c(-Inf, 1)
      value_range <- c(-Inf, variable[1])
    } else if (x >= variable[length(variable)]) {  # Check if 'x' is greater than or equal to the last element
      index_range <- c(length(variable), Inf)
      value_range <- c(variable[length(variable)], Inf)
    }
  }
  
  # Return the calculated 'index_range' and 'value_range' as a list
  return(list(index_range = index_range, value_range = value_range))
}





# Task 23 ===========================================================================================================================================
#########################################################################################
# Exercise 23 (Python Lecture_6)
# Run your program for an input array of 10000000 integers
# (if the value is too large, reduce it so that the calculations take place in a reasonable time) 
# and compare it to running it on an array of float values of the same size. 
# Is there any noticable difference in the time the two algorithm are running?
#########################################################################################
runtime_program <- function(v, x) {
  start_time <- Sys.time()
  find_pos_mod(variable = v, x = x)
  end_time <- Sys.time()
  elapsed_time <- end_time - start_time
  cat("Elapsed time:", elapsed_time, "seconds. \n")
  cat("When run with", length(v), "numbers of type", typeof(v), ".\n")
}
runtime_program(seq(10000000), 5000000)
runtime_program(seq(0,100, length.out = 10000000), 50)

runtime_program(seq(10000000), 8000000)
runtime_program(seq(0,100, length.out = 10000000), 80)

# Running the program with integers seems to be marginally faster.



# Task 24 ===========================================================================================================================================
#########################################################################################
# Exercise 24 and 25 (R Lecture_6)
# is the same as in Python's version, except that first you need 
# to correct the code of the binary search in the same
# manner as in Python's version of the program.
#########################################################################################
# Define a function that performs a binary search to find the index and value range for a given value, x, within a 1-dimensional array or vector
binary_search <- function(v, x) {
  # Check if the input 'v' is a valid 1-dimensional array or vector
  if (!(is.vector(v) || (is.array(v) && length(dim(v)) == 1) || (is.list(v) && length(v) > 0))) {
    stop("Parameter must be a 1-dimensional array or vector")
  }
  
  # Check if 'x' is greater than the last element in the vector
  if (v[length(v)] < x) {
    index_range <- c(length(v), Inf)
    value_range <- c(v[length(v)], Inf)
    return(list(index_range = index_range, value_range = value_range))
  }
  # Check if 'x' is smaller than the first element in the vector
  else if (v[1] > x) {
    index_range <- c(-Inf, 1)
    value_range <- c(-Inf, v[1])
    return(list(index_range = index_range, value_range = value_range))
  }
  # If 'x' is within the vector, perform a binary search
  else {
    start <- 1
    end <- length(v)
    
    while (start <= end) {
      mid <- (start + end) %/% 2
      if (v[mid] == x) {
        index_range <- c(mid, mid + 1)
        value_range <- c(v[mid], ifelse(mid == length(v), Inf, v[mid + 1]))
        return(list(index_range = index_range, value_range = value_range))
      }
      # If 'x' is smaller than the middle element, update 'end'
      else if (v[mid] > x) {
        end <- mid - 1
      }
      # If 'x' is larger than the middle element, update 'start'
      else {
        start <- mid + 1
      }
    }
    
    # If 'x' was not found in the vector, return the range where it should be inserted
    if (start > 1) {
      index_range <- c(start - 1, start)
      value_range <- c(v[start - 1], ifelse(start == length(v) + 1, Inf, v[start]))
    } else {
      # If 'start' is 1, then 'x' should be inserted before the first element
      index_range <- c(-Inf, 1)
      value_range <- c(-Inf, v[1])
    }
    return(list(index_range = index_range, value_range = value_range))
  }
}





# Task 26 ===========================================================================================================================================
#########################################################################################
# Exercise 26
# Run your program for an input array of 10000000 integers
# (if the value is too large, reduce it so that the calculations take place in a reasonable time) 
# and compare it to running it on an array of float values of the same size. 
# Is there any noticable difference in the time the two algorithm are running?
#########################################################################################
runtime_program2 <- function(v, x) {
  start_time <- Sys.time()
  binary_search(v=v, x=x)
  end_time <- Sys.time()
  elapsed_time <- end_time - start_time
  cat("Elapsed time:", elapsed_time, "seconds. \n")
  cat("When run with", length(v), "numbers of type", typeof(v), ".\n")
}
runtime_program2(seq(10000000), 5000000)
runtime_program2(seq(0,100, length.out = 10000000), 50)

# There is a noticable difference between the two algorithms. Binary search is significantly faster than previous code. In fact it is about 10 times faster (it varies a little bit from time to time, and also at which index the x lies. Binary search is not as dependent on the index as the previous algorithm because of the architecture of finding the position (diving the 'search window' in two each time.)


# Task 29 ===========================================================================================================================================
#########################################################################################
#Exercise 29. (R Lecture 7) Use 'detectCores()' to find out how many processors are available on your computer. 
#Report the outcome (my had 10). Rewrite the above code (see Lecture notes) to compute the integral discussed in Exercise 6. 
#Discuss the accuracy and the speed of the method of Riemann sums with the Monte Carlo one. 
library(parallel)
number_cores <- detectCores()
# My computer has 8 cores.

#Necessary modules for evaluatingtheperformance.
require(parallel)
require(microbenchmark)


# The function we want to intergrate. (The same as previous lab done in exercise 6).
f <- function(x) {
  return(log(x) + exp(x))
}

monte_carlo_integration <- function(n) {
  x_values <- runif(n, 1, 2)  # Uniformly sample points from [1,2]
  x_eval <- sapply(x_values, f)  # Compute f(x) for each sampled x
  integral_approximation <- (2-1) * mean(x_eval)  # Average and multiply by interval length
  return(integral_approximation)
}


# Parallelized Monte Carlo integration method
monte_carlo_parallel <- function(n) {
  require(purrr)
  num_cores <- detectCores() - 1
  num_simulations_per_core <- n %/% num_cores
  
  # Initiate a cluster of workers.
  cl <- makeCluster(num_cores)
  
  # Pass functions and variables to the seperate workers.
  clusterExport(cl, c("monte_carlo_integration", "f"))
  
  # Use parLapply to compute monte_carlo_integration in parallel.
  results <- parLapply(cl, rep(num_simulations_per_core, num_cores), function(each_n) {
    # Run monte_carlo_integration and return the result
    result <- monte_carlo_integration(each_n)
    return(result)
  })
  
  # Stop cluster.
  stopCluster(cl)
  
  # Compute means of each simulation.
  mean_results <- map_vec(results, mean)
  
  return(mean(mean_results))
}

# Compare the methods using a larger n for better accuracy
n <- 1e6  # Number of samples/simulations

print(paste("Monte Carlo method:", monte_carlo_integration(n)))
print(paste("Parallel Monte Carlo method:", monte_carlo_parallel(n)))
print(paste("The difference in computing-time between the two:", abs(monte_carlo_integration(n) - monte_carlo_parallel(n))))

# Comparison in speed using microbenchmark
# Measure execution-time for the Monte Carlo method with no parallel.
monte_carlo_time <- microbenchmark(
  ordinary = monte_carlo_integration(n),
  times = 100  
)

# Measure execution-time for the parallel Monte Carlo computation.
monte_carlo_parallel_time <- microbenchmark(
  parallel = monte_carlo_parallel(n),
  times = 100  
)

# Print each execution time.
print(monte_carlo_time)
print(monte_carlo_parallel_time)

# Comment on difference: 
# Surprisingly the calculations are a bit faster for the 'normal' method and the mean time is therefor lower.
# mean normal: 1.67 seconds, mean parallel: 1.82 seconds. 
# However one should notice that the parallel seems to be a bit more stable due to the lower range of max-min (normal intervall: 4.486-0.981, parallel intervall: 3.007 - 1.605. 





# Task 31 ===========================================================================================================================================
#########################################################################################
# Exercise 31. (R Lecture 7) Make comparison of the speed of different implementation of Fibonacci code in R and
# varying also the number of generated elements of the Fibonacci sequence. 
# Summarize your results in a simple table and draw the conclusions.
#########################################################################################
library(microbenchmark)
library(Rcpp)
sourceCpp('Fibonacci.cpp')
source('Fibonacci.R')

res_benchmark_1 <- microbenchmark::microbenchmark(Fibonacci_native(5),
                               Fibonacci(5), 
                               times=250)
microbenchmark::microbenchmark(Fibonacci_native(5),
                               Fibonacci(5), 
                               times=250)

res_benchmark_2 <- microbenchmark::microbenchmark(Fibonacci_native(10),
                                                  Fibonacci(10), 
                                                  times=250)
microbenchmark::microbenchmark(Fibonacci_native(10),
                               Fibonacci(10), 
                               times=250)

res_benchmark_3 <- microbenchmark::microbenchmark(Fibonacci_native(20),
                                                  Fibonacci(20), 
                                                  times=250)
microbenchmark::microbenchmark(Fibonacci_native(20),
                               Fibonacci(20), 
                               times=250)


library(ggplot2)
ggplot2::autoplot(res_benchmark_1) + ggtitle('Distribution of Runtime of Native R vs. C++')
ggplot2::autoplot(res_benchmark_2) + ggtitle('Distribution of Runtime of Native R vs. C++')
ggplot2::autoplot(res_benchmark_3) + ggtitle('Distribution of Runtime of Native R vs. C++')


# We can see that the C++ performs the calculation a lot faster. As we can see in the plots it seems like the difference of the running times increases as we increase n (compare differences when 5,10,20). Notice the different measure of unit of the benchmarking output.



############################################################################################################################################
#																	   #
#								Python - Code							   	   #
#																	   #
############################################################################################################################################

# -*- coding: utf-8 -*-
"""
Created on Tue Oct 10 15:20:58 2023

@author: 
"""

import os
import inspect
import time
import numpy as np
os.chdir('xxx')


# %% Exercise 20 
'''
#Exercise 20 (R & Python Lecture_6)
#One can use the command line to uppload a function. 
#For example, %run / source (Python/R) print_triangle would upload the function 
#defined above (see Lecture notes) if it is saved in a separate script with the name print_triangle.py / print_triangle.R (Python/R) . 
#Please, create such a script and run this script to upload the function defined in it. 
#Then invoke the function with several different values of the input.
'''
# Det här är ett eget script.
# def print_triangle(n):
#     for i in range(n+1):
#         print("∗"*i) 
        
# print_triangle(5)

runfile('print_triangle.py') # This demands the working directory being in the same folder as the script 'print_triangle.py'

# %% Exercise 21
'''
#Exercise 21 (Python Lecture_6)
#Create a script only with the function find_pos (see Lecture notes) saved in a separate 
#script that has the same name as the function. 
#Run this script to upload the definition. 
#Then invoke the function with several different values of 
#the input list of different lengths. Consider both real and integer numbers 
#in the input list.
'''
#======================    
# def find_pos(v,x):
#     for i in range(len(v)):
#         if v[i]>=x: return i

# v=[1,2,5,10]
# print(find_pos(v,-1))
# print(find_pos(v,4))
# print(find_pos(v,11))
#======================
# %run find_pos.py gives error-message
runfile('find_pos.py') # Same as earlier requires the working directory to be the folder as the script
print(find_pos(range(100),-1))
print(find_pos(range(100),4))
print(find_pos(range(1000),986))
print(find_pos(np.linspace(0, 100, 1000), 25.67))
print(find_pos(np.linspace(0, 100, 1000), 100))


# %% Exercise 22
'''
#Exercise 22 (Python Lecture_6)
#Modify the function find_pos so that it takes either list or 1-D
# array as the first argument, yields a tuple of two elements 
#(L,L+1) if the second argument x of the function 
#satisfies v[L]<=x<v[L+1], or ('-Inf',0) if x is smaller than 
#all elements in the first argument v, or (len(v),'Inf') 
#if x is larger than all elements in the list v. 
#Additionally to the index range, the function should also return 
#the corresponding value range.
'''
def find_pos_mod(v, x):
    try:
        # Check if 'v' is a 1-D NumPy array or a list
        if not ((isinstance(v, np.ndarray) and v.ndim == 1) or isinstance(v, list)):
            raise Exception('Parameter v must be a 1-D NumPy array or a list')
        
        # Initialize variables to store the index and value range
        index_range = None
        value_range = None
        
        # Loop through the elements of 'v'
        for i in range(len(v)):
            # Check if 'x' is greater than or equal to the current element
            if x >= v[i]:
                if i == len(v) - 1:
                    # 'x' is greater than or equal to the last element
                    index_range = (i, i + 1)
                    value_range = (v[i], float('inf'))
                else:
                    # 'x' is within the range of the current and next element
                    if x < v[i + 1]:
                        index_range = (i, i + 1)
                        value_range = (v[i], v[i + 1])
            else:
                if i == 0:
                    # 'x' is smaller than the first element
                    index_range = (float('-inf'), 0)
                    value_range = (float('-inf'), v[0])

        # If 'index_range' and 'value_range' are still None, 'x' falls outside the range
        if index_range is None or value_range is None:
            # 'x' is greater than the last element
            index_range = (len(v), float('inf'))
            value_range = (v[-1], float('inf'))
        
        return index_range, value_range
    
    except Exception as e:
        print(e)
   


# %% Exercise 23
'''
#Exercise 23 (Python Lecture_6)
#Run your program for an input array of 10000000 integers
(if the value is too large, reduce it so that the calculations take place in a reasonable time) 
# and compare it to running it on an array of float values of the same size. 
#Is there any noticable difference in the time the two algorithm are running?
'''
def runtime_program(v,x):
    import time
    start = time.time()
    find_pos_mod(v=v, x=x)
    end = time.time()
    run_time = end-start
    number_type = 'Integer' if all(isinstance(x, (int)) for x in v) else 'Float'
    print(f'Runtime for the function of {number_type}: {run_time:.10f} seconds')


runtime_program(np.linspace(0,100, 10000000), 50)
runtime_program(list(range(10000000)), 5000000)
# runtime_program(np.arange(0,10000000), 5000000)

# Here I use the values the x values to be 50 and 5 000 000 in order for the indexes to be same, 
# i.e. the loop to iterate equal amount of times. 
# We can see that the looping is significantly faster when looping through a list of integers compared to floats.


# %% Exercise 24
'''
#Exercise 24 (Python Lecture_6)
#Modify the function binary_search (see Lecture notes) so that it takes either list or 1-D array 
#as the first argument, yields a tuple of two elements (L,L+1) if the second 
#argument x of the function satisfies v[L]<=x<v[L+1], or ('-Inf',0) if x is 
#smaller than all elements in the first argument v, or (len(v),'Inf') if x is 
#larger than all elements in the list v. Additionally to the index range, 
#the function should also return the corresponding value range. 
#Run this function using the same inputs as in Exercise 23. 
#Are there any observable benefits of the new algorithm, 
#when compared with the previous one?
'''
def binary_search(v, x):
    try:
        if not ((isinstance(v, np.ndarray) and v.ndim == 1) or isinstance(v, list)):
            raise Exception('Parameter v must be a 1-D NumPy array or a list')

        if v[-1] < x:
            return ((len(v), float('inf')), (v[-1], float('inf')))
        elif v[0] > x:
            return ((float('-inf'), 0), (float('-inf'), v[0]))
        else:
            start, end = 0, len(v) - 1
            while start <= end:
                mid = (start + end) // 2
                if v[mid] == x:
                    return ((mid, mid + 1), (v[mid], v[mid + 1]))
                elif v[mid] > x:
                    end = mid - 1
                else:
                    start = mid + 1
            return ((end, start), (v[end], v[start]))
    except Exception as e:
        print(e)

def runtime_program2(v,x):
    import time
    start = time.time()
    binary_search(v=v, x=x)
    end = time.time()
    run_time = end-start
    number_type = 'Integer' if all(isinstance(x, (int)) for x in v) else 'Float'
    print(f'Runtime for the function of {number_type}: {run_time:.16f} seconds')


runtime_program2(np.linspace(0,100, 10000000), 50)
runtime_program2(list(range(10000000)), 5000000)

# There is a big difference in the running time of the two different algorithms. One (the earlier function ) is significantly slower.


# %% Exercise 25
'''
#Exercise 25 (Python & R Lecture_6)
#Benchmark both Python and R-version of the programs find_pos and binary_search (see Lecture notes).
#Are there significant differences between the performances on these two platforms.
'''







# %% Exercise 26
'''
# Exercise 26. (Python Lecture_7; BML model)
# The following is Python implementation of Biham–Middleton–Levine (BML) traffic model
# see the textbook for more details about the model
'''
import numpy as np
import matplotlib.pyplot as plt

class BML:
    def __init__(self, alpha, m, n):
        self.alpha = alpha
        self.shape = (m, n)
        self.initialize_lattice()

    def initialize_lattice(self):
        u = np.random.uniform(0.0, 1.0, self.shape)
        # instead of using default list, we use np.array to create the lattice
        self.lattice = np.zeros_like(u, dtype=int)
        # the parentheses below can’t be ignored
        self.lattice[(u > self.alpha) & (u <= (1.0 + self.alpha) / 2.0)] = 1
        self.lattice[u > (self.alpha + 1.0) / 2.0] = 2
        
        # Shape av storlek MxN som skapar ett gitter / grid / schackbräd
        # Slumptal genereras med uniform fördelning
        # Alpha bestämmer intervallet för vilka värden som ska tilldelas. Då det i vårt fall är 0.4 innebär att:
            # uniform slumptal: 0-0.4 ger en nolla på grid, 0.4-0.7 ger 1 på gitter, >0.7 ger en 2
            
        # Gitter / grid / schackbräda 'korrigeras' med värdena 0,1,2 baserat på slumptalen enligt ovan beskrivet.
        
        
    def odd_step(self):
        # please note that np.where returns a tuple which is immutable
        blue_index = np.where(self.lattice == 1)
        blue_index_i = blue_index[0] - 1
        blue_index_i[blue_index_i < 0] = self.shape[0] - 1
        blue_movable = self.lattice[(blue_index_i, blue_index[1])] == 0
        self.lattice[(blue_index_i[blue_movable],
                      blue_index[1][blue_movable])] = 1
        self.lattice[(blue_index[0][blue_movable],
                      blue_index[1][blue_movable])] = 0
        
        # Vi tar här ut index för vilka positioner som har ett värde om 1 (alltså det tilldelade värdet efter slumptalsgenereringen.)
        

    def even_step(self):
        red_index = np.where(self.lattice == 2)
        red_index_j = red_index[1] + 1
        red_index_j[red_index_j == self.shape[1]] = 0
        red_movable = self.lattice[(red_index[0], red_index_j)] == 0
        self.lattice[(red_index[0][red_movable],
                      red_index_j[red_movable])] = 2
        self.lattice[(red_index[0][red_movable],
                      red_index[1][red_movable])] = 0


    def plot_lattice(self):
        # Define colors for visualization
        colors = {0: 'white', 1: 'blue', 2: 'red'}
        
        # Create a figure and axis for the plot
        fig, ax = plt.subplots()
        
        # Create a grid of squares based on the lattice values
        for i in range(self.shape[0]):
            for j in range(self.shape[1]):
                square_color = colors[self.lattice[i, j]]
                ax.add_patch(plt.Rectangle((j, i), 1, 1, color=square_color, edgecolor='black'))
        
        # Set axis limits and labels
        ax.set_xlim(0, self.shape[1])
        ax.set_ylim(0, self.shape[0])
        ax.set_aspect('equal')
        ax.set_xticks(range(self.shape[1] + 1))  # +1 to include the last column
        ax.set_yticks(range(self.shape[0] + 1))  # +1 to include the last row
        ax.grid(which='both')
        
        # Show the plot
        plt.show()   

#run the previous code in the console, and create a Class 'BML'

bml = BML(0.4, 5, 5)
bml.lattice
#Execute the above commands two times and check whether the returned arrays differ.

# The arrays are not the same.

np.random.seed(2022)
bml = BML(0.4, 5, 5)
bml.lattice
#Execute the above commands two times and check whether the returned arrays differ.
#You should get the same matrix. Explain the impact of the "np.random.seed(2022)".

# When seeting the random seed we decide, in advance, the sampling algorithm. 
# This means the sampling algorithms are the same both times we run the lines which 
# is not the case in the lines above when not setting the random seed. This is 
# useful for reproducibility in order to get the same results every time, no 
# matter who/which computer is running the code. More specifically random seed 
# is determining the sampling algorithm in the np.random.uniform(0.0, 1.0, self.shape)
# defined in the class. 



# %% Exercise 27
'''
# Exercise 27. (Python Lecture_7; BML model) Execute commands below.

np.random.seed(2022)
bml = BML(0.4, 5, 5)
bml.lattice
bml.odd_step()
bml.lattice
bml.even_step()
bml.lattice

#Explain the impact of the bml.odd_step() and bml.even_step().
'''
np.random.seed(2022)
bml = BML(0.4, 5, 5)
bml.lattice
bml.odd_step()
bml.lattice
bml.even_step()
bml.lattice

# For us to be able to understand what the methods/instances are doing we 
# have to inspect the class defined in the above exercise (26). The odd-step and even-step are functioning like a coordinate plane.
# The coordinate plane is filled with 0,1,2 where 1 represents blue index and 2 represents red index. The blue and red oordinates moves over the whole coordinate plane
# in opposite directions (90 degree angle). The functions / methods instances checks wether there is a color (blue or red, meaning opposite colour) in the directions it wants to move.
# If there isn't a color in the next forward coordinate on the plane it can move forwards. This is represented by the:
    # blue_movable and red_movable within the class that is represented of a boolean value. It can move in the direction if true but cannot move forwards if false.

# As soon as there is an empty with no color in the direction it wants move, the color_movable boolean operator will be true and it will move to that positition.

# All in all, this can be seen something similar to a traffic light, when green light it moves represented by true, and if the red light is red (represented by false) it has to wait for it the light to be green.


# %% Exercise 28
'''
#Exercise 28. (Python Lecture_7; BML model) Experiment with the parameter 'alpha' 
and based on your experiments clarify what does it control.
'''
# As commented above, within the class, alpha decides of which values, generated by the uniform distribution, should be assigned the different colours. 
# It practically decides the different threshholds for the different colours. A higher alpha value gives a lower probability of assigning one or two in the initial lattice / gitter. 
# Meaning a low alpha value will assign many more colours meaning harder to move/a lot more cars with the traffic analogy. It will the be harder for 
# the colours to move because the probability of having a colour in the direction it wants to move is higher.


# Add the following instance to the original class to be able to plot it #
##########################################################################
    # def plot_lattice(self):
    #     # Define colors for visualization
    #     colors = {0: 'white', 1: 'blue', 2: 'red'}
        
    #     # Create a figure and axis for the plot
    #     fig, ax = plt.subplots()
        
    #     # Create a grid of squares based on the lattice values
    #     for i in range(self.shape[0]):
    #         for j in range(self.shape[1]):
    #             square_color = colors[self.lattice[i, j]]
    #             ax.add_patch(plt.Rectangle((j, -i - 1), 1, 1, color=square_color, edgecolor='black'))
        
    #     # Set axis limits and labels
    #     ax.set_xlim(0, self.shape[1])
    #     ax.set_ylim(-self.shape[0], 0)
    #     ax.set_aspect('equal')
    #     ax.set_xticks(range(self.shape[1]))
    #     ax.set_yticks(range(-self.shape[0], 0))
    #     ax.grid(which='both')
        
    #     # Show the plot
    #     plt.show()

##########################################################################

np.random.seed(2022)
bml = BML(0.4, 5, 5)
bml.lattice



bml = BML(0.2, 5, 5)
bml.plot_lattice()

bml = BML(0.3, 5, 5)
bml.plot_lattice()

bml = BML(0.4, 5, 5)
bml.plot_lattice()

# Here we can see that the alpha value determines how many 'coloured boxes' there will be. 
# Continuing on the traffic analogy alpha determines how much traffic there  is.

# Below code is made in order to get a better understanding of the steps that are done.
# Down below is made of two different cases, one where the grid is 5x5, and one with a 10x10 grid. 
# For each of these there are different alpha values.
# Notice that if wemany iterations the algorithm seems to reach a state where the boxes can no longer move in any direction.


def simulate_and_visualize(bml, num_steps):
    import time
    for step in range(num_steps):
        # Perform the odd step and visualize
        bml.odd_step()
        bml.plot_lattice()
        time.sleep(0.03)
        print(f"Iteration: {step+1}")
        # Perform the even step and visualize
        bml.even_step()
        bml.plot_lattice()
        time.sleep(0.03)
        print(f"Iteration: {step+1}")

simulate_and_visualize(BML(0.2, 5,5), 20)
simulate_and_visualize(BML(0.3, 5,5), 20)
simulate_and_visualize(BML(0.4, 5,5), 20)

simulate_and_visualize(BML(0.2, 10,10), 20)
simulate_and_visualize(BML(0.3, 10,10), 20)
simulate_and_visualize(BML(0.4, 10,10), 50)


# %% Exercise 30
'''
#Exercise 30. (Python Lecture_7) Summarize in two three sentences what are the 
# differences between 'laziness' and 'eagerness' of languages
# and reflect when one can prefer one over the other.
'''
# Laziness and eagerness are two different concepts/methods for programming languages. It is describing wether an 
# algorithm/calculation is computed as soon as it is encountered in a code-line chunk, or wait until the computed value is needed. 
# Eeagerness means it is computing the value as soon as it is encountered, even though it is not needed at that point in time,
# Laziness on the other hand computes the value only when the computaion is needed in order to compute the 'next calculation' based on that value. 
# Python embraces the eagerness approach.



